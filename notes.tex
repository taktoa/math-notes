\documentclass[]{article}

\usepackage{screenread}

\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e}
\usepackage{xcolor}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\definecolor{LinkColor}{HTML}{006090}

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{\usepackage[]{microtype}%
  \UseMicrotypeSet[protrusion]{basicmath}}{}
\PassOptionsToPackage{hyphens}{url}
\usepackage[unicode=true]{hyperref}
\hypersetup{
  unicode    = true,
  pdfborder  = {0 0 0},
  breaklinks = true,
  colorlinks = true,
  allcolors  = LinkColor
}
\IfFileExists{parskip.sty}{\usepackage{parskip}}{%
  \setlength{\parindent}{0pt}\setlength{\parskip}{6pt plus 2pt minus 1pt}}
\setlength{\emergencystretch}{3em}
\providecommand{\tightlist}{\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}

\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{mathtools}
\usepackage{amsmath}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\definecolor{AnswerColor}{HTML}{664411}

\newcommand{\answer}[1]{\color{AnswerColor} #1}
\newenvironment{answereq*}[0]{%
  \color{AnswerColor}\begin{equation*}}{\end{equation*}}

\newcommand{\atsign}[0]{@}

\usepackage[at]{easylist}

\newcommand{\taylor}[3]{%
  \ensuremath{\mathcal{T}_{{#1} \, \mathrm{at} \, {#2}}^{#3}}}

\usepackage{stmaryrd}

\newcommand{\semantic}[1]{\ensuremath{\llbracket {#1} \rrbracket}}

\newcommand{\textbs}[1]{{\sffamily\fontseries{sbc}\selectfont #1}}

\newcommand{\mathbs}[1]{\ensuremath{\text{\textbs{#1}}}}
\renewcommand{\mathtt}[1]{\ensuremath{\texttt{#1}}}

\newcommand{\mrs}[1]{\ensuremath{\mathnormal{#1}}} % Reset font to normal
\newcommand{\mbf}[1]{\ensuremath{\mathbf{#1}}}     % Boldface
\newcommand{\mbs}[1]{\ensuremath{\mathbs{#1}}}     % Bold + sans-serif
\newcommand{\mbb}[1]{\ensuremath{\mathbb{#1}}}     % Blackboard bold
\newcommand{\mtt}[1]{\ensuremath{\mathtt{#1}}}     % Teletype
\newcommand{\mrm}[1]{\ensuremath{\mathrm{#1}}}     % Serif ("roman")
\newcommand{\msf}[1]{\ensuremath{\mathsf{#1}}}     % Sans-serif
\newcommand{\msc}[1]{\ensuremath{\mathsc{#1}}}     % Small-caps
\newcommand{\mcl}[1]{\ensuremath{\mathcal{#1}}}    % Calligraphic
\newcommand{\msr}[1]{\ensuremath{\mathscr{#1}}}    % Script
\newcommand{\mfr}[1]{\ensuremath{\mathfrak{#1}}}   % Fraktur

\newcommand{\norm}[1]{\ensuremath{\lVert{} {#1} \rVert{}}}

\newcommand{\rmand}{\ensuremath{\mathrel{\mathrm{and}}}}

\newcommand{\tens}[0]{\otimes}
\newcommand{\comp}[0]{\circ}

\renewcommand{\empty}[0]{\ensuremath{\o}}
\newcommand{\join}[0]{\ensuremath{\mathrel{\sqcup}}}
\newcommand{\meet}[0]{\ensuremath{\mathrel{\sqcap}}}
\newcommand{\bigjoin}[0]{\ensuremath{{\sqcup}\,}}
\newcommand{\bigmeet}[0]{\ensuremath{{\sqcap}\,}}
\newcommand{\poset}[0]{\ensuremath{\mathrel{\sqsubseteq}}}
\newcommand{\tesop}[0]{\ensuremath{\mathrel{\sqsupseteq}}}

\newcommand{\catset}[0]{\ensuremath{\mathsf{Set}}}
\newcommand{\catmon}[0]{\ensuremath{\mathsf{Mon}}}
\newcommand{\catgrp}[0]{\ensuremath{\mathsf{Grp}}}
\newcommand{\catab}[0]{\ensuremath{\mathsf{Ab}}}
\newcommand{\cat}[1]{\ensuremath{\mathsf{#1}}}

\newcommand{\opcat}[1]{\ensuremath{{#1}^{\mathsf{op}}}}

\DeclareMathOperator{\interior}{Int}
\DeclareMathOperator{\closure}{Cl}
\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\homset}{Hom}
\DeclareMathOperator{\objects}{Ob}

\renewcommand{\complement}[1]{{{#1}^{c}}}

\newcommand{\degree}[3]{\ensuremath{\msf{deg}_{#2}^{#1}(#3)}}
\newcommand{\indegree}[3]{\ensuremath{\msf{ideg}_{#2}^{#1}(#3)}}
\newcommand{\outdegree}[3]{\ensuremath{\msf{odeg}_{#2}^{#1}(#3)}}

\usepackage{url}

\usepackage[
  backend=biber,
  bibencoding=utf8,
  style=numeric,
  citestyle=numeric-comp]{biblatex}

\addbibresource{notes.bib}

% Usage: \simplecite{URL}{label}{caption}
\newcommand{\simplecite}[3]{\bibitem{#2}\href{#1}{\textit{#3}}}

% Usage: \simpleref{label}{caption}
\newcommand{\simpleref}[2]{\hyperlink{#1}{#2}}

\DeclareMathOperator{\diag}{diag}

\DeclareMathOperator{\argmin}{arg\,min}

\newcommand{\define}[1]{\textbs{#1}}

\usepackage{todonotes}
\newlength{\fixmewidth}
\setlength{\fixmewidth}{0.7\textwidth}
\newcommand{\fixme}[1]{%
  \begin{minipage}[c]{\fixmewidth}%
  \todo[color=green!40,inline]{\textsc{fixme:} #1}%
  \end{minipage}}
\newcommand{\sfixme}[0]{%
  \begin{minipage}[c]{3.5em}%
  \todo[color=green!40,inline]{\textsc{fixme}}%
  \end{minipage}}


\begin{document}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Notation}

\begin{easylist}[itemize]
@ {%
  Differences in between common set-theoretic notation and what is used in
  this document:
}
@@ {%
  Usually, $f({-})$ is used to denote $x \mapsto f(x)$, where $x$ is fresh
  variable. \\ This document instead uses $f(\circ)$, since it can be less
  confusing in some cases.
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Probability Theory}

\begin{easylist}[itemize]
@ These notes are primarily based on the following sources:
@@ {%
  \href{https://web.math.princeton.edu/~nelson/books/rept.pdf}{%
    \textit{Radically Elementary Probability Theory}}
  by Edward Nelson
}
@@ {%
  The notes I wrote when I took UIUC IE 300: Analysis of Data.
}
@ {%
  A \define{finite probability space} is a tuple
  $(\Omega \in \catset, \mathrm{pr} : \Omega \to \mbb{R})$ such
  that $\sum \{\mrm{pr}(\omega) \mid \omega \in \Omega\} = 1$
  and $\forall \omega \in \Omega ~.~ \mathrm{pr}(\omega) > 0$.
}
@ {%
  A \define{random variable} on $\Omega$ is a function $X : \Omega \to \mbb{R}$.
}
@@ {%
  The \define{expectation} of a random variable $X$, denoted $\mbb{E}(X)$, is
  defined by
  \begin{equation*}
  \mbb{E}(X)
  = \sum \{ X(\omega) \cdot \mrm{pr}(\omega) \mid \omega \in \Omega \}
  \end{equation*}
  \vspace{-2em}
}
@ {%
  An \define{event} is a subset $A \subseteq \Omega$ of the set underlying a
  finite probability space.
}
@@ {%
  The \define{probability} of an event is defined by
  \begin{equation*}
  \mbb{P}(A)
  = \sum \{ \mrm{pr}(\omega) \mid \omega \in A \}
  \end{equation*}
  \vspace{-2em}
}
@@ {%
  For any event $A$, the \define{indicator function} of $A$, denoted $\chi_A$,
  is a random variable defined by
  \begin{equation*}
  \chi_A(\omega)
  = \left\{
  \begin{array}{lr}
    1 & \text{when } \omega \in    A \\
    0 & \text{when } \omega \notin A
  \end{array}
  \right\}
  \end{equation*}
  We can think of the probability of an event as being the expectation of the
  indicator function for that event: $\mbb{P}(A) = \mbb{E}(\chi_A)$.
}
@@ {%
  The \define{complementary event} for any event $A$, denoted $\complement{A}$,
  is defined by $\complement{A} = \Omega \setminus A$.
}
@ {%
  The set $\Omega \to \mbb{R}$ of all random variables on $\Omega$ is an
  $n$-dimensional vector space, where $n = \abs{\Omega}$.
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Graph Theory}

\begin{refsection}

\subsection{Introduction}

\begin{easylist}[itemize]
@ {%
  In the following definitions,
  $(R, [0_R, 1_R], [\msf{neg}_R], [{+}_R, {\times}_R])$
  will be an arbitrary rig (semiring). The rig of $m \times n$ $R$-valued
  matrices will be denoted by $\msf{Mat}_{m \times n}(R)$ or alternatively
  $n \multimap_R m$. Since ${+}_R$ is commutative, we can denote the arbitrary
  sum of a set $S \subseteq R$ by $\sum_R S$. In some cases, we may assume
  that $R$ is a commutative rig, in which case we are allowed to take the
  arbitrary product of a set $S \subseteq R$, denoted $\prod_R S$.
}
@ {%
  A \define{digraph} (also called a \define{directed graph} or for the purposes
  of these notes simply a \define{graph}) is a pair $G = (V, E)$ of a set of
  \define{vertices} $V \subset \catset$ (also called \define{nodes}) and a
  set of \define{edges} $E \subseteq V^2$. \\
  $V$ is the \define{vertex set} of $G$ and $E$ is the \define{edge set} of $G$.
  Since $E$ is a set of pairs, it is also sometimes called the
  \define{edge relation} of $G$.
}
@ {%
  An \define{undirected graph} is a graph $G = (V, E)$ such that
  if $(x, y) \in E$ then $(y, x) \in E$. \\
  Equivalently, a graph is undirected iff its edge relation is symmetric.
}
@ {%
  An \define{$R$-weighted graph} is a pair $G = ((V, E), \delta)$ of a graph
  $(V, E)$ and a function $\delta : E \to R$. \\
  We will sometimes call a graph ``unweighted'' to emphasize that it is not
  a weighted graph.
  We will sometimes refer to $(V, E)$ as the
  \define{underlying (unweighted) graph} of $G$.
  Similarly, $\delta$ is called the \define{(edge) weight function} of $G$.

  If $(M, {+}_M, 0_M)$ is a monoid, the \define{pair weight function} of
  an $M$-weighted graph $G = ((V, E), \delta)$, denoted $\pi_G : V^2 \to M$,
  is defined by:
  \begin{equation*}
  \pi_G(x, y) = \left\{\begin{array}{lr}
  \delta(x, y) & \text{ when } (x, y) \in    E \\
  0_M          & \text{ when } (x, y) \notin E \\
  \end{array}\right\}
  \end{equation*}
  This should be obvious from the notation, but if $R$ is a semiring, the pair
  weight function of an $R$-weighted graph will use the additive monoid of $R$.
}
@ {%
  The \define{complement} of an unweighted graph $G = (V, E)$
  is defined by $\overline{G} = (V, \{e \in V^2 \mid e \notin E\})$.
}
\end{easylist}

\subsection{Algebraic Graph Theory}

\begin{easylist}[itemize]
@ {%
  The \define{adjacency matrix} of an $R$-weighted graph
  $G = ((V = [1, n] \subset \mbb{N}, E \subseteq V^2), \delta \in E \to R)$
  is the unique $n \times n$ $R$-valued matrix $\msf{Adj}(G)$ such that for
  all $(i, j) \in V^2$, ${\msf{Adj}(G)}_{ij} = \pi_G(i, j)$.
}
@@ {%
  An adjacency matrix of an unweighted graph $G = (V, E)$ is just defined to be
  an adjacency matrix of $(V, E, (x, y) \mapsto 1_R)$ for any commutative
  ring $R$.
}
@@ {%
  \textbf{Theorem}: for any graph $G$, if $A$ and $B$ are both adjacency
  matrices of $P$, then there exists a permutation matrix $P$ such that
  $B = P^\top A P$.
}
@@ {%
  If, for some graph $G = (V \subset \catset, E \subseteq V^2)$, there is an
  obvious total order relation available for $V$, we will define the adjacency
  matrix of $G$ to be the adjacency matrix of the graph given by the unique
  bijection between $V$ and $[1, \card(V)]$ generated by the total order
  (i.e.: the sequence generated by sorting the elements of $V$ under the
  total order).

  Henceforth, when defining terminology relating to graphs, we will assume that
  the graph has $V = [1, n] \subset \mbb{N}_{+}$ for some $n \in \mbb{N}_{+}$,
  and then implicitly extend the defined notion to any graph with a totally
  ordered vertex set in the way we just did for $\msf{Adj}(-)$.
}
@@ {%
  \textbf{Theorem}:
  if a graph $G$ is undirected, then $\msf{Adj}(G)$ is a symmetric matrix.

  \textbf{Theorem}:
  if a graph $G$ is unweighted, then $\msf{Adj}(G)$ is a binary matrix.

  \textbf{Theorem}:
  if a graph $G$ has no edges ($G = ((V, \empty), \empty)$),
  then $\msf{Adj}(G)$ is a zero matrix.

  \textbf{Theorem}:
  if an unweighted graph $G$ is a ``complete graph'', that is, if there
  exists a set $V$ such that $G = (V, V^2)$, then $\msf{Adj}(G)$ is a matrix
  full of $1_R$.
}
@ {%
  The \define{weighted outdegree} of a node $x$ in an $R$-weighted graph
  $G = ((V, E), \delta)$ is defined to be the weighted sum of the set of edges
  that \textit{start} at $x$:
  $\outdegree{R}{G}{x} = \sum_R \{\delta(x, b) \mid (x, b) \in E\}$.

  The \define{weighted indegree} of a node $x$ in an $R$-weighted graph
  $G = ((V, E), \delta)$ is defined to be the weighted sum of the set of edges
  that \textit{end} at $x$:
  $\indegree{R}{G}{x} = \sum_R \{\delta(a, x) \mid (a, x) \in E\}$.

  The \define{weighted degree} of a node $x$ in a weighted \textit{undirected}
  graph $G$ is the same as its weighted indegree or its weighted outdegree:
  $\degree{R}{G}{x} = \indegree{R}{G}{x} = \outdegree{R}{G}{x}$.

  The \define{outdegree} and \define{indegree} in an unweighted graph
  $G = (V, E)$ are given by the weighted outdegree and weighted indegree of
  $((V, E), (x, y) \mapsto 1 \in \mbb{N})$.
  They are denoted by $\outdegree{}{G}{\circ}$ and $\indegree{}{G}{\circ}$
  respectively.

  Similarly, the \define{degree} in an unweighted undirected graph $G = (V, E)$
  is given by the weighted degree in $((V, E), (x, y) \mapsto 1 \in \mbb{N})$.
  The degree is denoted by $\degree{}{G}{\circ}$.

  Let's define the outdegree/indegree/degree of a node in a $W$-weighted graph
  to be the outdegree/indegree/degree of the node in the underlying unweighted
  graph.

  A graph $G$ is \define{$n$-regular} iff every node in $G$ has indegree $n$
  and outdegree $n$.

  A graph $G$ is \define{regular} iff there exists an $n \in \mbb{N}$ such
  that $G$ is $n$-regular.
}
@ {%
  The \define{indegree matrix} of an order-$n$ graph $G$ is given by
  $\msf{D}^\msf{in}(G) = \diag(\indegree{}{G}{1}, \dotsc, \indegree{}{G}{n})$.

  The \define{outdegree matrix} of an order-$n$ graph $G$ is given by
  $\msf{D}^\msf{out}(G) = \diag(\outdegree{}{G}{1}, \dotsc, \outdegree{}{G}{n})$.

  The \define{degree matrix} of an undirected graph $G = (([1, n], E), \delta)$
  is the same as its indegree matrix and its outdegree matrix:
  $ \msf{D}(G)
  = \msf{D}^\msf{in}(G)
  = \msf{D}^\msf{out}(G)
  = \diag(\degree{}{G}{1}, \dotsc, \degree{}{G}{n})$.
}
@ {%
  The \define{Laplacian matrix} of an undirected graph $G = (V, E)$
  is $\mathrm{\Delta}(G) = \msf{D}(G) - \msf{Adj}(G)$.

  On a directed graph $G = (V, E)$, the \define{indegree Laplacian matrix}
  is $\mathrm{\Delta}^\msf{in}(G) = \msf{D}^\msf{in}(G) - \msf{Adj}(G)$.
  The \define{outdegree Laplacian matrix} $\mathrm{\Delta}^\msf{out}(G)$
  is defined the same way.
}
@@ {%
  \textbf{Theorem}:
  $\mathrm{\Delta}(G)$ is a symmetric positive-semidefinite matrix.

  \textbf{Theorem}:
  The smallest eigenvalue of $\mathrm{\Delta}(G)$ is always $0$.

  \textbf{Theorem}:
  The product of the nonzero eigenvalues of $\mathrm{\Delta}(G)$ is equal to
  $\abs{G}$ times the number of spanning trees in $G$.

  \textbf{Theorem}:
  The number of connected components of $G$, $n$, is equal to the
  dimension of the nullspace of $\mathrm{\Delta}(G)$.
  Furthermore, the multiplicity of the $0$ eigenvalue in the spectrum of
  $\mathrm{\Delta}(G)$ is also equal to $n$.

  \textbf{Theorem}:
  $\mathrm{\Delta}(G)$ is always singular.
}
@@ {%
  The Laplacian matrix is like a discrete version of the Laplace operator.
  \sfixme{}
}
@ {%
  If $M$ is $n \times n$ $\mbb{C}$-valued matrix, then the \define{spectrum} of
  $M$ is its set of eigenvalues. The spectrum of $M$ is denoted by
  $\msf{Spec}(M) \in \{A \in \mbb{P}(\mbb{C}) \mid \card(A) = n\}$.
  If $R$ is a subring of $\mbb{C}$, then the spectrum of an $R$-valued matrix
  is defined by the inclusion map into $\mbb{C}$.

  The function mapping the spectrum of an $n \times n$ $R$-matrix $M$
  to the corresponding eigenvectors is denoted by
  $\eta_M : \msf{Spec}(M) \to \mbb{C}^n$.
  The function mapping the spectrum of $M$ to the corresponding eigenvalue
  multiplicities is denoted by $\kappa_M : \msf{Spec}(G) \to \mbb{N}$.

  Define $\msf{sort}(S \subseteq \mbb{C}) : [1, \card(S)] \to \mbb{C}$
  to be the function that sorts a set of complex numbers in increasing order
  of absolute value (i.e.: under the order induced by the total ordering of the
  reals when mapping with $(z \mapsto z \bar{z}) \in \mbb{C} \to \mbb{R}$).

  As shorthand, we will define the spectrum of a $R$-weighted graph
  $G = ((V, E), \delta)$, where $R \subseteq \mbb{C}$, to be the spectrum of
  its adjacency matrix; that is to say
  $\msf{Spec}(G) \equiv \msf{Spec}(\msf{Adj}(G))$.
  The $\eta_{\circ}$ and $\kappa_{\circ}$ functions are lifted to graphs in
  this way as well.

  If $A$ and $B$ have the same spectrum, we say that $A$ is \define{isospectral}
  to $B$; this is true whether $A$ and $B$ are graphs or matrices.

  % If $(C, [0_C, 1_C], [\msf{neg}_C, \msf{inv}_C], [{+}_C, {\times}_C])$
  % is an algebraically closed field and $G$ is a $C$-weighted graph,
  % then the \define{spectrum} of $G$ is the set of eigenvalues of $\msf{Adj}(G)$.
  % The spectrum of $G$ is denoted by
  % $\msf{Spec}(G) \in \{A \in \mbb{P}(C) \mid \card(A) = n\}$.
}
@@ {%
  \textbf{Note}: Most of the following statements come from
  \cite{brouwer-haemers}.
}
@@ {%
  \textbf{Theorem}:
  \fixme{spectral theorem, maybe in terms of a $C^\star$-algebra}
}
@@ {%
  \textbf{Theorem}:
  If $G = ((V, E), \delta)$, then
  $ \msf{Spec}(\overline{G})
  = \{\card(V) - v \mid v \in \msf{Spec}(\mrm{\Delta}(G))\}$.
}
\end{easylist}

\printbibliography[heading=subbibliography]

\end{refsection}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Differential Geometry}

\begin{easylist}[itemize]
@ {%
  A \define{topological space} is a pair $(S, \Omega_S \subseteq \mbb{P}(S))$
  such that:
}
@@ {%
  $\{\empty, S\} \subseteq \Omega$
}
@@ {%
  $\Omega$ is closed under arbitrary unions:
  $\forall \omega \subseteq \Omega ~.~ {\cup}(\omega) \in \Omega$
}
@@ {%
  $\Omega$ is closed under finite intersections:
  $\forall (A, B) \in \Omega^2 ~.~ A \cap B \in \Omega$
}
@ {%
  $\Omega$ is called the \define{topology} of $S$.
}
@ {%
  A topological space $(S, \Omega)$ is \define{Hausdorff} if, for any two
  distinct points $x$ and $y$ in $S$
}
@ {%
  A \define{topological manifold} is a locally Euclidean, paracompact, Hausdorff
}
@ {%
  A \define{$C^k$ manifold of dimension $n$} is a topological space equipped
  with
}
@ {%
  A \define{smooth manifold of dimension $n$} is another name for a
  $C^\infty$ manifold of dimension $n$.
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Linear Algebra}

\subsection{Matrices}

\begin{easylist}[itemize]
@ {%
  If $\mbs{s}$ is a commutative ring and $(m, n) \in \mbb{N}$,
  then $m \multimap_\mbs{s} n$ denotes the $\mbs{s}$-bimodule
  of $n \times m$ matrices. Sometimes, we will use the alternative notation
  $\mbs{M}_{m \times n}(\mbs{s}) = n \multimap_\mbs{s} m$.
}
@ {%
  \textbf{Theorem}:
  If $\mbs{s}$ is a field, then $m \multimap_\mbs{s} n$ is a vector space with
  $\mbs{s}$ as its field of scalars.
  Equivalently, $\msf{Vect}_\mbs{s}$ is a closed category (which means that
  it has an internal hom).
}
@ {%
  \textbf{Theorem}:
  Every matrix in $m \multimap_\mbs{s} n$ corresponds to a linear map
  in $\mbs{s}^m \to \mbs{s}^n$. For a matrix $M$, this linear map is given
  by $v \mapsto M \cdot v$. Composition of these linear maps corresponds to
  the matrix product.
}
@ {%
 There are several categories whose morphisms can be thought of as matrices:
}
@@ {%
  $\msf{Mat}_\mbs{s}$ is the category for which the objects are elements of the
  set $\{\mbs{s}^n \mid n \in \mbb{N}\}$, the hom-set between $\mbs{s}^x$ and
  $\mbs{s}^y$ is $\mbs{M}_{y \times x}(\mbs{s})$, and composition of morphisms
  is given by matrix multiplication.
}
@@ {%
  $\msf{Vect}_\mbs{s}$ is the category of vector spaces with linear maps as
  morphisms and composition of morphisms given by ordinary function composition.

  This might seem like a category relevant to matrices, but it isn't, as not
  only are there vector spaces in $\msf{Vect}_\mbs{s}$ that are
  infinite-dimensional, but there are vector spaces in $\msf{Vect}_\mbs{s}$
  whose dimension is uncountable!

  For example, define $\mbs{Unc}$ to be the vector space whose set of vectors is
  defined by
  $\{f \in \mbb{R} \to \mbb{R} \mid \card(\{x \in \mbb{R} \mid f(x) \neq 0\}) \in \mbb{N}\}$,
  whose addition is pointwise, and whose multiplication is pointwise.
  Since $\{(y \mapsto \delta(x, y)) \mid x \in \mbb{R}\}$ is a basis for
  $\mbs{Unc}$, where $\delta(x, y) = [x = y]$ is the Kronecker delta function
  on $\mbb{R}$, and $x \mapsto (y \mapsto \delta(x, y))$ is a bijection, and all
  the bases of a vector space must have the same cardinality as the dimension of
  the vector space, it must be the case that dimension of $\mbs{Unc}$ is
  $\abs{\mbb{R}}$, which is uncountable.

  While the concept of infinite matrices might seem reasonable, the idea of
  a matrix with uncountably many columns is not reasonable. Thus, an exposition
  of $\msf{Mat}_\mbs{s}$ needs to talk about $\msf{FinVect}_\mbs{s}$, the full
  subcategory of $\msf{Vect}_\mbs{s}$ consisting of only the finite-dimensional
  vector spaces (a full subcategory has the same hom-sets as its supercategory).

  Now we can describe $\msf{Mat}_\mbs{s}$ as the quotient
  of $\msf{FinVect}_\mbs{s}$ by the equivalence relation given by isomorphisms
  in $\msf{FinVect}_\mbs{s}$. Thus, $\msf{Mat}_\mbs{s}$ is the skeleton
  of $\msf{FinVect}_\mbs{s}$, which is unique up to isomorphism of categories.
}
\end{easylist}

\subsection{Matrix Product}

\begin{easylist}[itemize]
@ FIXME
\end{easylist}

\subsection{Kronecker Product}

\begin{easylist}[itemize]
@ {%
  If $A \in m \multimap_\mbs{s} n$ and $B \in p \multimap_\mbs{s} q$, then the
  \define{Kronecker product} of $A$ and $B$ is defined by
  \begin{align*}
    A \otimes B
    & \in m p \multimap n q \\
    A \otimes B
    & = \mathsf{flatten}{\left(\begin{bmatrix}
    A_{11} B & \cdots & A_{1n} B \\
    \vdots   & \ddots & \vdots   \\
    A_{m1} B & \cdots & A_{mn} B \\
    \end{bmatrix}\right)}
  \end{align*}
  where
  $ \mathsf{flatten}
  \in \mbs{M}_{a \times b}(\mbs{M}_{x \times y}(\mbs{s}))
  \to \mbs{M}_{a x \times b y}(\mbs{s})$
  is the function that ``flattens'' a block matrix into a matrix of scalars,
  and $A_{xy}$ is the scalar coordinate of $A$ at position $(x, y)$.
}
@ {%
  The Kronecker product can be used to make a tensor product for
  $\msf{Mat}_\mbs{s}$, thus making it a (non-strict) monoidal closed category,
  in the following way:
}
@@ {%
  The tensor unit is the \fixme{object in $\msf{Mat}_\mbs{s}$}.
}
@@ {%
  The tensor product bifunctor $\otimes$ acts on objects of
  $\msf{Mat}_\mbs{s}$ by
  \begin{align*}
    \mbs{s}^m \otimes \mbs{s}^n & = (\mbs{s}^m \times \mbs{s}^n) / \phi \\
    {} & \phi((k x, y), (x, k y)) \\
  \end{align*}
  \vspace{-2em}
}
@@ {%
  The tensor product bifunctor $\otimes$ acts on morphisms of
  $\msf{Mat}_\mbs{s}$, which are matrices, via the Kronecker product.
}
@@ {%
  The associator and unitors are the obvious ones.
}
@@ {%
}
@ There are a large number of identities involving the Kronecker product:
@@ {%
  Since the Kronecker product is a tensor product, it is bilinear:
  \begin{align*}
    A \otimes (B + C)       & = A \otimes B + A \otimes C \\
    (A + B) \otimes C       & = A \otimes C + B \otimes C \\
    (r A) \otimes (s B)     & = r s (A \otimes B)
  \end{align*}
  and it is associative:
  \begin{align*}
    (A \otimes B) \otimes C & = A \otimes (B \otimes C)
  \end{align*}
  \vspace{-2em}
}
@@ {%
  Although the Kronecker product is \textit{not} commutative, $A \otimes B$
  is always permutation-equivalent to $B \otimes A$.
  In other words, for every pair of matrices $A \in m \multimap_\mbs{s} n$
  and $B \in p \multimap_\mbs{s} q$, there always exist permutation matrices
  $P \in n q \multimap_\mbs{s} n q$ and $Q \in m p \multimap_\mbs{s} m p$
  such that $A \otimes B = P \cdot (B \otimes A) \cdot Q$. If $A$ and $B$ are
  square, then $P = Q^{-1} = Q^\top$ and $A \otimes B$ is thus permutation
  similar to $B \otimes A$.
  I'm not sure, but I think that this means that
}
@@ {%
  The matrix product ($\cdot$) and Kronecker product ($\otimes$) obey the
  \define{mixed product property}, which says that for any appropriately
  shaped matrices $A$, $B$, $C$, and $D$:
  \begin{equation*}
  (A \otimes B) \cdot (C \otimes D) = (A \cdot C) \otimes (B \cdot D)
  \end{equation*}
  Equivalently, if $\msf{Mat}_\mbs{s}$ is thought of as a closed monoidal
  category with the Kronecker product as its tensor product, then
  $\msf{Mat}_\mbs{s}$ is a symmetric monoidal closed category.
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Abstract Algebra}

\subsection{Ideals}

\begin{easylist}[itemize]
@ {%
  An \define{ideal} $I$ of a ring $R$ should be thought of as a particular kind
  of subset of a ring.
}
@ {%
  Specifically, for some ring $(R, +, {}\cdot{})$, a set $I$ is a
  \define{two-sided ideal} of $R$ if it satisfies two conditions:
}
@@ \textbf{Subgroup}: $(I, +)$ is a subgroup of $(R, +)$
@@ {%
  \textbf{Absorption}: For any $r \in R$ and any $i \in I$, $r \cdot i$ and
  $i \cdot r$ are both elements of $I$.
}
@ {%
  We can generalize this to the notion of a \define{left ideal} and a
  \define{right ideal}. A left ideal only requires $r \cdot i \in I$, while a
  right ideal only requires $i \cdot r \in I$.
}
@ {%
  The canonical example of an ideal is that of the even integers $2\mbb{Z}$,
  which are an ideal in $\mbb{Z}$.
}
@@ {%
  To see why this is, note that addition is closed over $2\mbb{Z}$, and that
  the additive inverse of an even integer is also even. Thus, $(2\mbb{Z}, +)$
  is a subgroup of $(\mbb{Z}, +)$. The other factor is that multiplying any
  number by an even number gives you another even number, so the absorption
  condition is satisfied.
}
@ {%
  More generally, for any integer $n$ in $\mbb{Z}$, $n\mbb{Z}$ (i.e.: the set
  $\{n \cdot x \mid x \in \mbb{Z}\}$) is an ideal in $\mbb{Z}$.
}
@ {%
  In some sense, ideals generalize the idea of the set of all values
  divisible by a given value.
}
@ Other examples:
@@ {%
  For any ring $R$, $R$ is trivially an ideal of $R$.
  This is called the \define{unit ideal} of $R$.
}
@@ {%
  For any ring $R$, $\{0_R\}$ is an ideal of $R$.
  This is called the \define{zero ideal} of $R$.
}
@@ {%
  Denote the ring of all univariate polynomials with real coefficients
  by $\mbb{R}[x]$. Then the set of all such polynomials divisible by $x^2 + 1$
  is an ideal in $\mbb{R}[x]$.
}
@ Some types of ideals:
@@ {%
  A \define{proper ideal}  is one that is not the unit ideal.
  A \define{nonzero ideal} is one that is not the zero ideal.
}
@@ {%
  The \define{maximal ideal} of a ring is the largest possible proper ideal
  for that ring.
}
@@ {%
  The \define{minimal ideal} of a ring is the smallest possible nonzero ideal
  for that ring.
}
@@ {%
  A \define{prime ideal} is an ideal $I$ such that for any $(a, b) \in R^2$,
  $a \cdot b \in I$ implies $a \in I$ or $b \in I$.
}
@@ {%
  A \define{radical} or \define{semiprime ideal} is an ideal $I$ such that
  for any $a \in R$, $a^n \in I$ implies $a \in I$.
}
@@ A \define{principal ideal} is an ideal with one generator.
@ {%
  The \define{quotient of a ring $R$ by an ideal $I$} is
  $(R / \{(a, b) \in R^2 \mid (a - b) \in I\}, +, {}\cdot{})$.
}
@ Products and sums
@@ {%
  Any two ideals $I$ and $J$ have a sum, defined as
  $I + J = \{a + b \mid a \in I \land b \in J\}$.
}
@@ {%
  Any two ideals $I$ and $J$ have a product, defined as
  \begin{equation*}
  I \times J = \{
    \psi(0) + \cdots + \psi(n)
    \mid   n \in \mbb{N}
    \rmand \phi \in \mbb{N} \to I \times J
    \rmand \psi = \pi \comp \phi
  \}
  \end{equation*}
  where $\pi : R^2 \to R$ is defined as $\pi(a, b) = a \cdot b$
}
@@ {%
  Note that $(I \cup J) \subseteq (I + J)$
  and $(I \times J) \subseteq (I \cap J)$.
}
@ The set of ideals of a ring $R$ is denoted $\mbb{I}_R$.
@ {%
  For convenience, we will define a function
  $\Phi : (A^2 \to A) \times A \to \mbb{P}(A) \to A$ by:
  \begin{equation*}
    {\Phi(f, e)(\varnothing) = e}
    ~ ~ \rmand ~ ~
    {\Phi(f, e)(\{x\} \cup X) = f(x, \Phi(f, e)(X))}
  \end{equation*}
  where $x \in A$ and $X \subseteq \mbb{P}(A)$.
  This is known as the \define{fold} of a binary operator $f$ with a unit $e$.
}
@ {%
  $(\mbb{I}_R, \subseteq, \Phi(+, \{0_R\}), \Phi(\cap, R), \{0_R\}, R)$
  is a complete modular lattice.
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Locale Theory}

\begin{easylist}[itemize]
@ These notes are primarily based on the following sources:
@@ {%
  \href{https://dl.acm.org/citation.cfm?id=64996}{%
    \textit{Topology via Logic}}
  by Steven Vickers
}
@ For some set $A$ and relation $(\#) \subseteq A \times A$:
@@ $(\#)$ is \define{reflexive} iff $\forall x \in A ~.~ x \mathrel{\#} x$.
@@ {%
  $(\#)$ is \define{transitive} iff
  $\forall (x, y, z) \in A^3 ~.~
  ((x \mathrel{\#} y) \land (y \mathrel{\#} z)) \implies (x \mathrel{\#} z)$.
}
@@ {%
  $(\#)$ is \define{symmetric} iff for all $(x, y) \in A^2$,
  $(x \mathrel{\#} y) \iff (y \mathrel{\#} x)$.
}
@@ {%
  $(\#)$ is \define{anti-symmetric} iff for all $(x, y) \in A^2$ such that
  $x \mathrel{\#} y$ and $y \mathrel{\#} x$, we have $x = y$.
}
@ {%
  A \define{preorder} is a set $P$ equipped with a relation $(\poset)$ that is
  both reflexive and transitive.
}
@@ {%
  Alternatively, a preorder can be thought of as a category $C$ in which \\
  $\forall (X, Y) \in {\objects(C)}^2 ~.~ \abs{\homset(X, Y)} \le 1$.

  For this reason, preorders are sometimes called \define{thin categories}.
}
@@ {%
  The \define{opposite preorder} for a preorder $P = (X, \poset)$ is defined as
  $\opcat{P} = (X, \tesop)$.
}
@@ {%
  A function $f : (P, \poset_P) \to (Q, \poset_Q)$ is \define{monotone} iff
  for every $(x, y) \in P^2$, it is the case that
  $x \poset_P y \implies f(x) \poset_Q f(y)$.

  The category of thin categories has monotone functions as morphisms.

  In other words, a functor between thin categories is a monotone function.
}
@ A \define{poset} is a preorder in which $(\poset)$ is anti-symmetric.
@@ {%
  Alternatively, a poset can be thought of as a category in which for any
  distinct pair of objects $(X, Y)$, we have
  $\abs{\homset(X, Y) \uplus \homset(Y, X)} \le 1$.
}
@@ {%
  Every preorder $(P, \poset)$ gives rise to a poset $(P / {\equiv}, \poset)$,
  where $a \equiv b \iff (a \poset b) \land (b \poset a)$.
}
@@ {%
  In a given poset $P$, with $X \subseteq P$ and $a \in P$, $a$ is a
  \define{lower bound} (resp. \define{upper bound}) for $X$ iff for any
  $x \in X$, $a \poset x$ (resp. $x \poset a$).
}
@@ {%
  A lower bound $a$ of $X$ is a \define{meet} if it is greater than or equal to
  any other lower bound.
}
@@ {%
  A \define{join} is dual to a meet; if $a$ is a join for $X$ in $P$, then
  $a$ is a meet for $X$ in $\opcat{P}$.
}
@ {%
  A \define{pseudolattice} is a poset in which every nonempty finite subset has
  a meet and a join.
}
@ {%
  A \define{meet-/join-semilattice} is a poset in which every finite subset
  has a meet/join.
}
@ {%
  A \define{lattice} is a poset that is both a meet-semilattice and a
  join-semilattice. Alternatively, a lattice is a pseudolattice with empty meets
  and joins (which correspond to unique maximal and minimal elements).
}
@ {%
  \textbf{Theorem}:
  A poset $P$ is a pseudolattice if it has binary meets and joins.
}
@ {%
  \textbf{Corollary}:
  If $P$ also has empty meets and joins, it is a lattice.
}
@ {%
  Thus, we will heretofore denote all finite meets and joins by binary operators
  $(\meet)$ and $(\join)$.
}
@ {%
  Infinite meets and joins will look like ${\meet}(X)$ and ${\join}(X)$
  for some $X \subseteq P$.
}
@ {%
  For lattices $L_1$ and $L_2$, a function $f : L_1 \to L_2$ is a
  \define{lattice homomorphism} if and only if for every $(a, b)$ in $L_1^2$,
  $f(a \meet_1 b) = f(a) \meet_2 f(b)$ and $f(a \join_1 b) = f(a) \join_2 f(b)$.

  A lattice homomorphism is a monotone function that respects binary meets
  and binary joins.

  The category of lattices, $\cat{Lat}$, has lattice homomorphisms
  as its morphisms.
}
@ Note that the set of all pseudolattices is closed under $(\opcat{\circ})$.
@ {%
  A poset $P$ is a \define{frame} iff every subset has join, every finite subset
  has a meet, and binary meets distribute over joins.
}
@@ In general, if $F$ is a frame, $\opcat{F}$ is not a frame.
@@ {%
  One notable exception is the \define{powerset frame} on a set $X$,
  $\mbb{P}(X)$.
}
@@ {%
  $\mbf{1} = (\{\star\}, \empty)$, the \define{inconsistent frame}, so named
  because it has $\bot = \top$.
}
@@ $\mbf{2} = (\{\bot,\top\}, \{(\bot, \top)\})$, the \define{Sierpinski frame}.
@ {%
  A \define{topology} $\Omega$ on a set $X$ is a frame such that $\Omega$ is a
  subframe of $\mbb{P}(X)$.
}
@ A \define{topological space} is a set $X$ equipped with a topology $\Omega$.
@ The elements of $\Omega$ are known as the \define{open subsets} of $X$.
@ For a poset $P$ where $x \in P$ and $S \subseteq P$:
@@ {%
  ${\uparrow}(x) = \{y \in P \mid x \poset y\}$
  is the \define{upper closure} of $x$.
}
@@ {%
  ${\uparrow}(S) = \{y \in P \mid (\exists x \in S ~ . ~ x \poset y)\}$
  is the \define{upper closure} of $S$.
}
@@ {%
  The \define{lower closure} of $x$ and $S$, denoted by ${\downarrow}(\circ)$,
  is just the upper closure in $\opcat{P}$.
}
@ Examples of topologies:
@@ The \define{discrete topology} is $\Omega = \mbb{P}(X)$.
@@ The \define{indiscrete topology} is $\Omega = \empty$.
@@ {%
  The \define{Alexandrov topology} on a poset $P$ is defined as
  $\Omega = \{{\uparrow}(x) \mid x \in P\}$.
}
@ {%
  We will heretofore denote the topology associated with any given topological
  space $X$ by $\Omega_X$.
}
@ {%
  The \define{interior} of a subset $S$ of a topological space $X$ is
  $\interior(S) = \cup \{A \in \Omega_X \mid A \subseteq S\}$
}
@@ Note that $\interior(S)$ is always the largest open set contained in $S$.
@ A subset $F \subseteq X$ is \define{closed} iff its complement is open.
@ A subset is \define{clopen} iff it is both open and closed.
@ {%
  The \define{topological closure} of a subset $S \subseteq X$ is
  $\closure(S) = \complement{(\interior(\complement{S}))}$
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\end{document}

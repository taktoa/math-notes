\documentclass[]{article}

\usepackage{screenread}

\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e}
\usepackage{xcolor}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\definecolor{LinkColor}{HTML}{006090}

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{\usepackage[]{microtype}%
  \UseMicrotypeSet[protrusion]{basicmath}}{}
\PassOptionsToPackage{hyphens}{url}
\usepackage[unicode=true]{hyperref}
\hypersetup{
  unicode    = true,
  pdfborder  = {0 0 0},
  breaklinks = true,
  colorlinks = true,
  allcolors  = LinkColor
}
\IfFileExists{parskip.sty}{\usepackage{parskip}}{%
  \setlength{\parindent}{0pt}\setlength{\parskip}{6pt plus 2pt minus 1pt}}
\setlength{\emergencystretch}{3em}
\providecommand{\tightlist}{\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}

\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{mathtools}
\usepackage{amsmath}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\definecolor{AnswerColor}{HTML}{664411}

\newcommand{\answer}[1]{\color{AnswerColor} #1}
\newenvironment{answereq*}[0]{%
  \color{AnswerColor}\begin{equation*}}{\end{equation*}}

\newcommand{\atsign}[0]{@}

\usepackage[at]{easylist}

\newcommand{\taylor}[3]{%
  \ensuremath{\mathcal{T}_{{#1} \, \mathrm{at} \, {#2}}^{#3}}}

\usepackage{stmaryrd}

\newcommand{\semantic}[1]{\ensuremath{\llbracket {#1} \rrbracket}}

\newcommand{\textbs}[1]{{\sffamily\fontseries{sbc}\selectfont #1}}

\newcommand{\mathbs}[1]{\ensuremath{\text{\textbs{#1}}}}
\renewcommand{\mathtt}[1]{\ensuremath{\texttt{#1}}}

\newcommand{\mrs}[1]{\ensuremath{\mathnormal{#1}}} % Reset font to normal
\newcommand{\mbf}[1]{\ensuremath{\mathbf{#1}}}     % Boldface
\newcommand{\mbs}[1]{\ensuremath{\mathbs{#1}}}     % Bold + sans-serif
\newcommand{\mbb}[1]{\ensuremath{\mathbb{#1}}}     % Blackboard bold
\newcommand{\mtt}[1]{\ensuremath{\mathtt{#1}}}     % Teletype
\newcommand{\mrm}[1]{\ensuremath{\mathrm{#1}}}     % Serif ("roman")
\newcommand{\msf}[1]{\ensuremath{\mathsf{#1}}}     % Sans-serif
\newcommand{\msc}[1]{\ensuremath{\mathsc{#1}}}     % Small-caps
\newcommand{\mcl}[1]{\ensuremath{\mathcal{#1}}}    % Calligraphic
\newcommand{\msr}[1]{\ensuremath{\mathscr{#1}}}    % Script
\newcommand{\mfr}[1]{\ensuremath{\mathfrak{#1}}}   % Fraktur

\newcommand{\norm}[1]{\ensuremath{\lVert{} {#1} \rVert{}}}

\newcommand{\rmand}{\ensuremath{\mathrel{\mathrm{and}}}}

\newcommand{\tens}[0]{\otimes}
\newcommand{\comp}[0]{\circ}

\renewcommand{\empty}[0]{\ensuremath{\o}}
\newcommand{\join}[0]{\ensuremath{\mathrel{\sqcup}}}
\newcommand{\meet}[0]{\ensuremath{\mathrel{\sqcap}}}
\newcommand{\bigjoin}[0]{\ensuremath{{\sqcup}\,}}
\newcommand{\bigmeet}[0]{\ensuremath{{\sqcap}\,}}
\newcommand{\poset}[0]{\ensuremath{\mathrel{\sqsubseteq}}}
\newcommand{\tesop}[0]{\ensuremath{\mathrel{\sqsupseteq}}}

\newcommand{\catset}[0]{\ensuremath{\mathsf{Set}}}
\newcommand{\catmon}[0]{\ensuremath{\mathsf{Mon}}}
\newcommand{\catgrp}[0]{\ensuremath{\mathsf{Grp}}}
\newcommand{\catab}[0]{\ensuremath{\mathsf{Ab}}}
\newcommand{\cat}[1]{\ensuremath{\mathsf{#1}}}

\newcommand{\opcat}[1]{\ensuremath{{#1}^{\mathsf{op}}}}

\DeclareMathOperator{\interior}{Int}
\DeclareMathOperator{\closure}{Cl}
\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\homset}{Hom}
\DeclareMathOperator{\objects}{Ob}

\renewcommand{\complement}[1]{{{#1}^{c}}}

\newcommand{\degree}[3]{\ensuremath{\mrm{deg}_{#2}^{#1}(#3)}}
\newcommand{\indegree}[3]{\ensuremath{\mrm{ideg}_{#2}^{#1}(#3)}}
\newcommand{\outdegree}[3]{\ensuremath{\mrm{odeg}_{#2}^{#1}(#3)}}

\usepackage{url}

\usepackage[
  backend=biber,
  bibencoding=utf8,
  style=numeric,
  citestyle=numeric-comp]{biblatex}

\addbibresource{notes.bib}

% Usage: \simplecite{URL}{label}{caption}
\newcommand{\simplecite}[3]{\bibitem{#2}\href{#1}{\textit{#3}}}

% Usage: \simpleref{label}{caption}
\newcommand{\simpleref}[2]{\hyperlink{#1}{#2}}

\DeclareMathOperator{\diag}{diag}

\DeclareMathOperator{\argmin}{arg\,min}

\newcommand{\define}[1]{\textbs{#1}}

\usepackage{todonotes}
\newlength{\fixmewidth}
\setlength{\fixmewidth}{0.7\textwidth}
\newcommand{\fixme}[1]{%
  \begin{minipage}[c]{\fixmewidth}%
  \todo[color=green!40,inline]{\textsc{fixme:} #1}%
  \end{minipage}}
\newcommand{\sfixme}[0]{%
  \begin{minipage}[c]{3.5em}%
  \todo[color=green!40,inline]{\textsc{fixme}}%
  \end{minipage}}


\begin{document}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Notation}

\begin{easylist}[itemize]
@ {%
  Differences in between common set-theoretic notation and what is used in
  this document:
}
@@ {%
  Usually, $f({-})$ is used to denote $x \mapsto f(x)$, where $x$ is fresh
  variable. \\ This document instead uses $f(\circ)$, since it can be less
  confusing in some cases.
}
@@ {%
  $\msf{Fin}(n)$ for any $n \in \mbb{N}$ denotes the set
  $\{k \in \mbb{N} \mid 0 \le k < n\}$.
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Computer Science}

\begin{easylist}[itemize]
@ Graph coloring
@@ {%
  A \define{coloring} of a graph $G = (V, E)$ is a map $\phi : V \to \mbb{N}$
  such that for any $(s, t) \in E$, $\phi(s) \neq \phi(t)$. In other words, it
  is an assignment of numbers (``colors'') to vertices in a graph such that no
  two neighboring vertices are assigned the same number.

  The set of all colorings of $G$ is denoted $\msf{Coloring}(G)$.

  The \define{order} of a coloring $\phi$ is the maximum element of $\mbb{N}$
  assigned to any vertex of the graph;
  i.e.: $\mrm{order}(\phi) = \max(\msf{Im}(\phi))$.

  The \define{chromatic number} $\chi(G)$ of a graph $G$ is defined to be the
  order of the smallest coloring of $G$;
  i.e.: $\chi(G) = \min\{\mrm{order}(\phi) \mid \phi \in \mrm{Coloring}(G)\}$.

  A coloring $\phi$ of a graph $G$ is said to be \define{optimal} if the order
  of $\phi$ is equal to the chromatic number of $G$.
}
@@ {%
  For any graph $G = (V, E)$, an ordering
  $\sigma : \msf{Fin}(\abs{V}) \leftrightarrow V$
  induces a coloring $\gamma_\sigma : V \to \mbb{N}$ of $G$ called the
  \define{greedy coloring}, which is defined by
  \begin{equation*}
  \gamma_\sigma(v) = \min (\mbb{N} - \{ \gamma_\sigma(\sigma(k)) \mid k \in \msf{Fin}(\sigma^{-1}(v)) \wedge (\sigma(k), v) \in E \})
  \end{equation*}
  This coloring iterates through the vertices via the ordering $\sigma$,
  assigning each vertex the smallest color that is not used by any of its
  neighbors.
}
@@ {%
  A \define{perfect elimination ordering} of a graph is an ordering of the
  vertices of a graph such that for each vertex $v$ in the ordering, $v$ and all
  of its neighbors that occur after it in the ordering form a clique.
}
@@ {%
  Theorem: greedily coloring a graph using a perfect elimination ordering always
  gives an optimal coloring of that graph.
}
@@ {%
  A \define{chordal graph} is a graph where every induced cycle has exactly
  three vertices; i.e.: every cycle of length 4 or more has a \define{chord}: an
  edge that is not part of the cycle but connects two vertices in the cycle.
}
@@ {%
  Theorem: a perfect elimination ordering of a chordal graph can be computed in
  polynomial time using the \define{lexicographic BFS} algorithm.
}
@@ Corollary: chordal graphs can be optimally colored in polynomial time.
@@ {%
  An \define{interval graph} is a graph $G = (V, E)$ for which there exists an
  assignment $\iota : V \to \mbb{R} \times \mbb{R}$ called an
  \define{interval model} such that
  $(s, t) \in E$ iff $I(\iota(s)) \cap I(\iota(t)) \neq \o$
  where $I : \mbb{R} \times \mbb{R} \to \mbb{P}(\mbb{R})$
  is the mapping from the data of an interval to the actual subset
  of $\mbb{R}$ that that interval represents.
}
@@ Theorem: every interval graph is a chordal graph.
@@ {%
  Theorem: if you have an interval model of an interval graph, then sorting the
  intervals by their left endpoint gives a perfect elimination ordering of the
  interval graph.
}
%@ Shortest Common Superstring
%@@ {%
%  The \define{shortest common superstring} of a set $S \subset \Sigma^{\star}$
%  of strings, denoted $\mrm{scs}(S)$, is defined to be the shortest string
%  that contains every element of $S$ as a substring.
%}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Probability Theory}

\begin{easylist}[itemize]
@ These notes are primarily based on the following sources:
@@ {%
  \href{https://web.math.princeton.edu/~nelson/books/rept.pdf}{%
    \textit{Radically Elementary Probability Theory}}
  by Edward Nelson
}
@@ {%
  The notes I wrote when I took UIUC IE 300: Analysis of Data.
}
@ {%
  A \define{finite probability space} is a tuple
  $(\Omega \in \catset, \mathrm{pr} : \Omega \to \mbb{R})$ such
  that $\sum \{\mrm{pr}(\omega) \mid \omega \in \Omega\} = 1$
  and $\forall \omega \in \Omega ~.~ \mathrm{pr}(\omega) > 0$.
}
@ {%
  A \define{random variable} on $\Omega$ is a function $X : \Omega \to \mbb{R}$.
}
@@ {%
  The \define{expectation} of a random variable $X$, denoted $\mbb{E}(X)$, is
  defined by
  \begin{equation*}
  \mbb{E}(X)
  = \sum \{ X(\omega) \cdot \mrm{pr}(\omega) \mid \omega \in \Omega \}
  \end{equation*}
  \vspace{-2em}
}
@ {%
  An \define{event} is a subset $A \subseteq \Omega$ of the set underlying a
  finite probability space.
}
@@ {%
  The \define{probability} of an event is defined by
  \begin{equation*}
  \mbb{P}(A)
  = \sum \{ \mrm{pr}(\omega) \mid \omega \in A \}
  \end{equation*}
  \vspace{-2em}
}
@@ {%
  For any event $A$, the \define{indicator function} of $A$, denoted $\chi_A$,
  is a random variable defined by
  \begin{equation*}
  \chi_A(\omega)
  = \left\{
  \begin{array}{lr}
    1 & \text{when } \omega \in    A \\
    0 & \text{when } \omega \notin A
  \end{array}
  \right\}
  \end{equation*}
  We can think of the probability of an event as being the expectation of the
  indicator function for that event: $\mbb{P}(A) = \mbb{E}(\chi_A)$.
}
@@ {%
  The \define{complementary event} for any event $A$, denoted $\complement{A}$,
  is defined by $\complement{A} = \Omega \setminus A$.
}
@ {%
  The set $\Omega \to \mbb{R}$ of all random variables on $\Omega$ is an
  $n$-dimensional vector space, where $n = \abs{\Omega}$.
}
@ {%
  FIXME: If $Z_1 \sim \mcl{N}(\mu_1, \sigma_1^2)$
  and $Z_2 \sim \mcl{N}(\mu_2, \sigma_2^2)$,
  then $Z_1 + Z_2 \sim \mcl{N}(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Graph Theory}

\begin{refsection}

\subsection{Introduction}

\begin{easylist}[itemize]
@ {%
  In the following definitions,
  $(R, [0_R, 1_R], [\mrm{neg}_R], [{+}_R, {\times}_R])$
  will be an arbitrary rig (semiring). The rig of $m \times n$ $R$-valued
  matrices will be denoted by $\mrm{Mat}_{m \times n}(R)$ or alternatively
  $n \multimap_R m$. Since ${+}_R$ is commutative, we can denote the arbitrary
  sum of a set $S \subseteq R$ by $\sum_R S$. In some cases, we may assume
  that $R$ is a commutative rig, in which case we are allowed to take the
  arbitrary product of a set $S \subseteq R$, denoted $\prod_R S$.
}
@ {%
  A \define{digraph} (also called a \define{directed graph} or for the purposes
  of these notes simply a \define{graph}) is a pair $G = (V, E)$ of a set of
  \define{vertices} $V \subset \catset$ (also called \define{nodes}) and a
  set of \define{edges} $E \subseteq V^2$. \\
  $V$ is the \define{vertex set} of $G$ and $E$ is the \define{edge set} of $G$.
  Since $E$ is a set of pairs, it is also sometimes called the
  \define{edge relation} of $G$.
}
@ {%
  An \define{undirected graph} is a graph $G = (V, E)$ such that
  if $(x, y) \in E$ then $(y, x) \in E$. \\
  Equivalently, a graph is undirected iff its edge relation is symmetric.
}
@ {%
  An \define{$R$-weighted graph} is a pair $G = ((V, E), \delta)$ of a graph
  $(V, E)$ and a function $\delta : E \to R$. \\
  We will sometimes call a graph ``unweighted'' to emphasize that it is not
  a weighted graph.
  We will sometimes refer to $(V, E)$ as the
  \define{underlying (unweighted) graph} of $G$.
  Similarly, $\delta$ is called the \define{(edge) weight function} of $G$.

  If $(M, {+}_M, 0_M)$ is a monoid, the \define{pair weight function} of
  an $M$-weighted graph $G = ((V, E), \delta)$, denoted $\pi_G : V^2 \to M$,
  is defined by:
  \begin{equation*}
  \pi_G(x, y) = \left\{\begin{array}{lr}
  \delta(x, y) & \text{ when } (x, y) \in    E \\
  0_M          & \text{ when } (x, y) \notin E \\
  \end{array}\right\}
  \end{equation*}
  This should be obvious from the notation, but if $R$ is a semiring, the pair
  weight function of an $R$-weighted graph will use the additive monoid of $R$.
}
@ {%
  The \define{complement} of an unweighted graph $G = (V, E)$
  is defined by $\overline{G} = (V, \{e \in V^2 \mid e \notin E\})$.
}
\end{easylist}

\subsection{Algebraic Graph Theory}

\begin{easylist}[itemize]
@ {%
  The \define{adjacency matrix} of an $R$-weighted graph
  $G = ((V = [1, n] \subset \mbb{N}, E \subseteq V^2), \delta \in E \to R)$
  is the unique $n \times n$ $R$-valued matrix $\msf{Adj}(G)$ such that for
  all $(i, j) \in V^2$, ${\msf{Adj}(G)}_{ij} = \pi_G(i, j)$.
}
@@ {%
  An adjacency matrix of an unweighted graph $G = (V, E)$ is just defined to be
  an adjacency matrix of $(V, E, (x, y) \mapsto 1_R)$ for any commutative
  ring $R$.
}
@@ {%
  \textbf{Theorem}: for any graph $G$, if $A$ and $B$ are both adjacency
  matrices of $P$, then there exists a permutation matrix $P$ such that
  $B = P^\top A P$.
}
@@ {%
  If, for some graph $G = (V \subset \catset, E \subseteq V^2)$, there is an
  obvious total order relation available for $V$, we will define the adjacency
  matrix of $G$ to be the adjacency matrix of the graph given by the unique
  bijection between $V$ and $[1, \card(V)]$ generated by the total order
  (i.e.: the sequence generated by sorting the elements of $V$ under the
  total order).

  Henceforth, when defining terminology relating to graphs, we will assume that
  the graph has $V = [1, n] \subset \mbb{N}_{+}$ for some $n \in \mbb{N}_{+}$,
  and then implicitly extend the defined notion to any graph with a totally
  ordered vertex set in the way we just did for $\msf{Adj}(-)$.
}
@@ {%
  \textbf{Theorem}:
  if a graph $G$ is undirected, then $\msf{Adj}(G)$ is a symmetric matrix.

  \textbf{Theorem}:
  if a graph $G$ is unweighted, then $\msf{Adj}(G)$ is a binary matrix.

  \textbf{Theorem}:
  if a graph $G$ has no edges ($G = ((V, \empty), \empty)$),
  then $\msf{Adj}(G)$ is a zero matrix.

  \textbf{Theorem}:
  if an unweighted graph $G$ is a ``complete graph'', that is, if there
  exists a set $V$ such that $G = (V, V^2)$, then $\msf{Adj}(G)$ is a matrix
  full of $1_R$.
}
@ {%
  The \define{weighted outdegree} of a node $x$ in an $R$-weighted graph
  $G = ((V, E), \delta)$ is defined to be the weighted sum of the set of edges
  that \textit{start} at $x$:
  $\outdegree{R}{G}{x} = \sum_R \{\delta(x, b) \mid (x, b) \in E\}$.

  The \define{weighted indegree} of a node $x$ in an $R$-weighted graph
  $G = ((V, E), \delta)$ is defined to be the weighted sum of the set of edges
  that \textit{end} at $x$:
  $\indegree{R}{G}{x} = \sum_R \{\delta(a, x) \mid (a, x) \in E\}$.

  The \define{weighted degree} of a node $x$ in a weighted \textit{undirected}
  graph $G$ is the same as its weighted indegree or its weighted outdegree:
  $\degree{R}{G}{x} = \indegree{R}{G}{x} = \outdegree{R}{G}{x}$.

  The \define{outdegree} and \define{indegree} in an unweighted graph
  $G = (V, E)$ are given by the weighted outdegree and weighted indegree of
  $((V, E), (x, y) \mapsto 1 \in \mbb{N})$.
  They are denoted by $\outdegree{}{G}{\circ}$ and $\indegree{}{G}{\circ}$
  respectively.

  Similarly, the \define{degree} in an unweighted undirected graph $G = (V, E)$
  is given by the weighted degree in $((V, E), (x, y) \mapsto 1 \in \mbb{N})$.
  The degree is denoted by $\degree{}{G}{\circ}$.

  Let's define the outdegree/indegree/degree of a node in a $W$-weighted graph
  to be the outdegree/indegree/degree of the node in the underlying unweighted
  graph.

  A graph $G$ is \define{$n$-regular} iff every node in $G$ has indegree $n$
  and outdegree $n$.

  A graph $G$ is \define{regular} iff there exists an $n \in \mbb{N}$ such
  that $G$ is $n$-regular.
}
@ {%
  The \define{indegree matrix} of an order-$n$ graph $G$ is given by
  $\msf{D}^\mrm{in}(G) = \diag(\indegree{}{G}{1}, \dotsc, \indegree{}{G}{n})$.

  The \define{outdegree matrix} of an order-$n$ graph $G$ is given by
  $\msf{D}^\mrm{out}(G) = \diag(\outdegree{}{G}{1}, \dotsc, \outdegree{}{G}{n})$.

  The \define{degree matrix} of an undirected graph $G = (([1, n], E), \delta)$
  is the same as its indegree matrix and its outdegree matrix:
  $ \msf{D}(G)
  = \msf{D}^\mrm{in}(G)
  = \msf{D}^\mrm{out}(G)
  = \diag(\degree{}{G}{1}, \dotsc, \degree{}{G}{n})$.
}
@ {%
  The \define{Laplacian matrix} of an undirected graph $G = (V, E)$
  is $\mathrm{\Delta}(G) = \msf{D}(G) - \msf{Adj}(G)$.

  On a directed graph $G = (V, E)$, the \define{indegree Laplacian matrix}
  is $\mathrm{\Delta}^\mrm{in}(G) = \msf{D}^\mrm{in}(G) - \msf{Adj}(G)$.
  The \define{outdegree Laplacian matrix} $\mathrm{\Delta}^\mrm{out}(G)$
  is defined the same way.
}
@@ {%
  \textbf{Theorem}:
  $\mathrm{\Delta}(G)$ is a symmetric positive-semidefinite matrix.

  \textbf{Theorem}:
  The smallest eigenvalue of $\mathrm{\Delta}(G)$ is always $0$.

  \textbf{Theorem}:
  The product of the nonzero eigenvalues of $\mathrm{\Delta}(G)$ is equal to
  $\abs{G}$ times the number of spanning trees in $G$.

  \textbf{Theorem}:
  The number of connected components of $G$, $n$, is equal to the
  dimension of the nullspace of $\mathrm{\Delta}(G)$.
  Furthermore, the multiplicity of the $0$ eigenvalue in the spectrum of
  $\mathrm{\Delta}(G)$ is also equal to $n$.

  \textbf{Theorem}:
  $\mathrm{\Delta}(G)$ is always singular.
}
@@ {%
  The Laplacian matrix is like a discrete version of the Laplace operator.
}
@ {%
  If $M$ is $n \times n$ $\mbb{C}$-valued matrix, then the \define{spectrum} of
  $M$ is its set of eigenvalues. The spectrum of $M$ is denoted by
  $\msf{Spec}(M) \in \{A \in \mbb{P}(\mbb{C}) \mid \card(A) = n\}$.
  If $R$ is a subring of $\mbb{C}$, then the spectrum of an $R$-valued matrix
  is defined by the inclusion map into $\mbb{C}$.

  The function mapping the spectrum of an $n \times n$ $R$-matrix $M$
  to the corresponding eigenvectors is denoted by
  $\eta_M : \msf{Spec}(M) \to \mbb{C}^n$.
  The function mapping the spectrum of $M$ to the corresponding eigenvalue
  multiplicities is denoted by $\kappa_M : \msf{Spec}(G) \to \mbb{N}$.

  Define $\mrm{sort}(S \subseteq \mbb{C}) : [1, \card(S)] \to \mbb{C}$
  to be the function that sorts a set of complex numbers in increasing order
  of absolute value (i.e.: under the order induced by the total ordering of the
  reals when mapping with $(z \mapsto z \bar{z}) \in \mbb{C} \to \mbb{R}$).

  As shorthand, we will define the spectrum of a $R$-weighted graph
  $G = ((V, E), \delta)$, where $R \subseteq \mbb{C}$, to be the spectrum of
  its adjacency matrix; that is to say
  $\msf{Spec}(G) \equiv \msf{Spec}(\msf{Adj}(G))$.
  The $\eta_{\circ}$ and $\kappa_{\circ}$ functions are lifted to graphs in
  this way as well.

  If $A$ and $B$ have the same spectrum, we say that $A$ is \define{isospectral}
  to $B$; this is true whether $A$ and $B$ are graphs or matrices.

  % If $(C, [0_C, 1_C], [\mrm{neg}_C, \mrm{inv}_C], [{+}_C, {\times}_C])$
  % is an algebraically closed field and $G$ is a $C$-weighted graph,
  % then the \define{spectrum} of $G$ is the set of eigenvalues of $\msf{Adj}(G)$.
  % The spectrum of $G$ is denoted by
  % $\msf{Spec}(G) \in \{A \in \mbb{P}(C) \mid \card(A) = n\}$.
}
@@ {%
  \textbf{Note}: Most of the following statements come from
  \cite{brouwer-haemers}.
}
@@ {%
  \textbf{Theorem}:
  \fixme{spectral theorem, maybe in terms of a $C^\star$-algebra}
}
@@ {%
  \textbf{Theorem}:
  If $G = ((V, E), \delta)$, then
  $ \msf{Spec}(\overline{G})
  = \{\card(V) - v \mid v \in \msf{Spec}(\mrm{\Delta}(G))\}$.
}
\end{easylist}

\printbibliography[heading=subbibliography]

\end{refsection}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Differential Geometry}

\subsection{Point-Set Topology}

\begin{easylist}[itemize]
@ {%
  A \define{topological space} is a pair $(S, \Omega_S \subseteq \mbb{P}(S))$
  such that:
}
@@ {%
  $\{\empty, S\} \subseteq \Omega$
}
@@ {%
  $\Omega$ is closed under arbitrary unions:
  $\forall \omega \subseteq \Omega ~.~ {\cup}(\omega) \in \Omega$
}
@@ {%
  $\Omega$ is closed under finite intersections:
  $\forall (A, B) \in \Omega^2 ~.~ A \cap B \in \Omega$
}
@ {%
  $\Omega$ is called the \define{topology} of $S$.
  Elements of $\Omega$ are called \define{open sets}.
}
@ {%
  If $(S, \Omega)$ is a topological space and $X \in \Omega$ and $X \neq S$,
  then $X$ is an \define{open subset} in $(S, \Omega)$.
}
@ {%
  If $(S, \Omega)$ is a topological space, then a subset $U \subset S$
  \define{neighborhood} of $p \in S$ if there exists an open subset of
  $X$ of $(S, \Omega)$ such that $p \in X$ and $X \subset U$.

  If a open subset is also a neighborhood of $p$, then it is said to
  be an \define{open neighborhood} of $p$.
}
@ {%
  An \define{open cover} of a topological space is a collection of open subsets
  such that the union of all the open subsets is the entire space.
}
@ {%
  An open cover $C = {\{U_i \subset S\}}_{i \in I}$ is \define{locally finite}
  if for every $p \in S$ there exists a neighborhood $N$ of $p$ such that the
  cardinality of $\{U_i \in C \mid U_i \cap N \neq \empty\}$ is finite.

  In other words, an open cover is locally finite if every neighborhood
  intersects only finitely many elements of the cover.
}
@ {%
  A \define{refinement} of an open cover $C$ of a space $(S, \Omega)$ is an
  open cover $R$ of $(S, \Omega)$ such that for every $U_R \in R$ there exists
  a $U_C \in C$ such that $U_R \subset U_C$.
}
@ {%
  A \define{continuous map} $f$ from a topological space $(X, \Omega_X)$
  to a topological space $(Y, \Omega_Y)$ is a function $f : X \to Y$ such
  that, for every open subset $U \subset Y$, the preimage of $U$ under $f$
  is an open subset of $X$.
}
@ {%
  A \define{homeomorphism} is a continuous map that is also an isomorphism.

  In other words, a homeomorphism is a continuous map $f : X \to Y$ such that
  there exists a continuous map $g : Y \to X$ and $g \comp f = \mathrm{id}_X$
  and $f \comp g = \mathrm{id}_Y$.

  If $f : X \simeq Y$, then $f$ is a homeomorphism between $X$ and $Y$.
}
@ {%
  A \define{basis} of a topology is a collection of open subsets such that every
  open subset in the topology is an (arbitrary) union of elements in the basis.

  A \define{subbasis} of a topology is a collection of open subsets such that
  every open subset in the topology is an (arbitrary) union of finite
  intersections of elements in the subbasis.

  If $B$ is a basis, then an element of $B$ is called a
  \define{basic open subset}.

  If $B$ is a subbasis, then an element of $B$ is called a
  \define{subbasic open subset}.

  A topology $\Omega$ is \define{generated} by $B$ if
  $B$ is a basis of $\Omega$.
}
@ {%
  A \define{metric space} is a topological space $(S, \Omega)$ equipped with a
  \define{metric} $d : S \times S \to \mbb{R}$, which is a function for which
  the following conditions all hold:
}
@@ {%
  The \define{non-negativity} axiom:
  for every $(x, y) \in S^2$, $d(x, y) \ge 0$.
}
@@ {%
  The \define{identity of indiscernables}:
  for every $(x, y) \in S^2$, $d(x, y) = 0$ iff $x = y$.
}
@@ {%
  The \define{symmetry} axiom:
  for every $(x, y) \in S^2$, $d(x, y) = d(y, x)$.
}
@@ {%
  The \define{triangle inequality} axiom:
  for every $(x, y, z) \in S^3$, $d(x, z) \le d(x, y) + d(y, z)$.
}
@ {%
  The \define{open ball} in a metric space $M = ((S, \Omega), d)$ with
  \define{center} $c \in S$ and \define{radius} $r \in \mbb{R}_{+}$ is
  the open subset $B(c, r)$ of $(S, \Omega)$ defined by
  $B(c, r) = \{p \in S \mid d(c, p) < r\}$.
}
@ {%
  A topological space $(S, \Omega)$ is said to be \define{metrizable} if it
  can be equipped with a metric $d$ such that $\Omega$ is generated by the
  collection of open balls in $S$:
  $\{B(c, r) \subset S \mid c \in S \land 0 < r < \infty\}$.
}
\end{easylist}

\subsection{Manifolds and Bundles}

\begin{easylist}[itemize]
@ {%
  A topological space $(S, \Omega)$ is a
  \define{topological manifold of dimension $n$}
  iff the following three conditions all hold:
}
@@ {%
  $(S, \Omega)$ is \define{Hausdorff}:
  for any two points $x$ and $y$ in $S$, if, for
  every open neighborhood $U$ of $x$ in $S$ and
  every open neighborhood $V$ of $y$ in $S$,
  $U \cap V \neq \empty$, then $x = y$.
}
@@ {%
  $(S, \Omega)$ is \define{paracompact}:
  for every open cover $C$ of $(S, \Omega)$, there exists a refinement of $C$
  that is locally finite.
}
@@ {%
  $(S, \Omega)$ is \define{locally Euclidean}:
  for every $p \in S$, there exists an open neighborhood $U$ such that there
  exists a homeomorphism $\phi : U \to \mbb{R}^n$.
}
@ {%
  \textbf{Theorem}: every topological manifold is metrizable.
}
@ {%
  A \define{local coordinate chart} of an open subset $U$ in a topological
  manifold of dimension $n$ is a homeomorphism $\phi : U \to \mbb{R}^n$.

  If $\phi_A : A \to \mbb{R}^n$ and $\phi_B : B \to \mbb{R}^n$ are two
  coordinate charts of a topological manifold $M$, then $\phi_A$ and $\phi_B$
  are \define{compatible} iff there exists a \define{gluing homeomorphism}
  $g : \phi_A(A \cap B) \simeq \phi_B(A \cap B)$.

  An \define{atlas} is an open cover $C$ of a topological manifold such that
  every $U \in C$ has a coordinate chart $\phi_U$ and for every $(A, B) \in C^2$
  if $A \cap B \neq \empty$ then $\phi_A$ is compatible with $\phi_B$.

  Every topological manifold of dimension $n$ has at least one atlas.
}
@ {%
  A \define{$k$-fold differentiable manifold of dimension $n$} is a topological
  manifold of dimension equipped with an atlas such that the gluing functions
  of the atlas are all $k$ times differentiable.

  If $k = \infty$, then we call it a \define{smooth manifold of dimension $n$}.
}
@ {%
  A \define{topological group} is a group $G$ whose underlying set is equipped
  with a topology $\Omega_G$ such that the addition operator ${+_G} : G^2 \to G$
  is a continuous map from ${(G, \Omega_G)}^2$ to $(G, \Omega_G)$ and the
  negation operator ${-_G} : G \to G$ is a continuous map from $(G, \Omega_G)$
  to itself.

  Alternatively, a topological group is a group object in the category of
  topological spaces $\cat{Top}$. From now on, we will define other types of
  groups in this way, to avoid redundancy.
}
@ {%
  If $B = (S_B, \Omega_B)$ and $F = (S_F, \Omega_F)$ are a topological spaces,
  then a \define{fiber bundle} $b$ is a pair of a topological space $E_b$,
  called the \define{total space} of $b$, and a continuous surjection
  $\pi_b : E \to B$, called the \define{projection map} of $b$, such that for
  every $x \in E$, there is an open neighborhood $U \subset B$ of $\pi_b(x)$
  (called the \define{trivializing neighborhood} of $x$) and there exists a
  homeomorphism $\phi : \pi_b^{-1}(U) \simeq U \times F$, called a
  \define{local trivialization}, such that
  $((a, b) \mapsto a) \comp \phi = \pi_b$.

  In other words, a fiber bundle is a continuous surjection between two
  topological spaces $E$ and $B$ such that, for some topological space $F$,
  $E$ locally looks like $B \times F$.
}
@ {%
  If $S$ is a set and $G$ is a group, then a \define{$G$-action} is any
  function $a : G \times S \to S$ such that $a(0_G, x) = x$ and
  $a(p +_G q, x) = a(p, a(q, x))$ for all $(p, q) \in G^2$ and all $x \in S$.

  If $G \in \cat{Grp}$, then $\mbf{B}(G)$ is the groupoid with one object
  $\star$ such that the automorphism group of $\star$ is isomorphic to $G$.

  Another way of thinking about group actions is that the action of a group $G$
  in a category $C$ is a functor $\rho : \mbf{B}(G) \to C$. The set $S$ in the
  original definition of a group action is just $\rho(\star)$.

  A group action is \define{effective} if the functor $\rho$ is faithful.

  Classically, an object of a (finitely cocomplete) category $C$ is said to be
  \define{inhabited} iff it is not the initial object of $C$.

  A group action is \define{transitive} if $C$ is cartesian closed and
  $\rho(\star)$ is inhabited and for every $x, y : 1 \to \rho(\star)$ in $C$,
  there exists a $g : \star \to \star$ such that $y = \rho(g) \comp x$.
}
@ \fixme{Talk about vector bundles and tangent bundles here}
\end{easylist}

\subsection{Lie Theory}

\begin{easylist}[itemize]
@ {%
  A \define{Lie group} is a group object internal to $\cat{Diff}$.
}
@ {%
  A \define{Lie algebra} is a vector space $\mfr{g}$ over a field $F$ equipped
  with an operator $[\circ, \circ] : \mfr{g}^2 \to \mfr{g}$, called the
  \define{Lie bracket}, that satisfies the following conditions:
}
@@ {%
  The Lie bracket is \define{bilinear}:
  for all $a, b \in F$ and all $x, y, z \in \mfr{g}$,
  $[a x + b y, z] = a [x, z] + b [y, z]$ and
  $[x, a y + b z] = a [x, y] + b [x, z]$.
}
@@ {%
  The Lie bracket is \define{alternating}:
  for all $x \in \mfr{g}$, $[x, x] = 0_\mfr{g}$.
}
@@ {%
  The \define{Jacobi identity} holds:
  for all $x, y, z \in \mfr{g}$,
  $[x, [y, z]] + [z, [x, y]] + [y, [z, x]] = 0$
}
@ \fixme{More Lie theory goes here}
\end{easylist}

\subsection{Tensor/Exterior/Clifford Algebra}

\begin{easylist}[itemize]
@ \sfixme
\end{easylist}

\subsection{Riemannian Geometry}

\begin{easylist}[itemize]
@ {%
  \fixme{Define the dual of a vector space}
}
@ {%
  \fixme{Define the tangent space of a point on a manifold}
}
@ {%
  A \define{pseudo-Riemannian manifold} $M$ is a smooth manifold equipped with
  an $M$-indexed collection of functions $g_p : {T_p(M)}^2 \to \mbb{R}$, called
  the \define{metric tensor}, on the tangent vector space at every point $p$
  such that the following conditions hold:
}
@@ {%
  The metric tensor is \define{smooth}:
  for all $p \in M$, $g_p$ is a morphism in $\cat{Diff}$.
}
@@ {%
  The metric tensor is \define{bilinear}:
  for all $p \in M$ and all $a, b \in \mbb{R}$ and all $x, y, z \in T_p(M)$,
  $g_p(a x + b y, z) = a g_p(x, z) + b g_p(y, z)$ and
  $g_p(x, a y + b z) = a g_p(x, y) + b g_p(x, z)$.
}
@@ {%
  The metric tensor is \define{symmetric}:
  for all $p \in M$ and all $x, y \in T_p(M)$, $g_p(x, y) = g_p(y, x)$.
}
@@ {%
  The metric tensor is \define{non-degenerate}:
  for all $p \in M$ and all $x \in T_p(M)$,
  if $g_p(x, y) = 0$ for every $y \in T_p(M)$, then $x = 0$.
}
@ {%
  A metric tensor is \define{positive definite} for every $p \in M$ and every
  $v \in T_p(M)$, $g_p(v, v) > 0$ or $v = 0$.

  A \define{Riemannian manifold} is a pseudo-Riemannian manifold with a
  positive definite metric tensor.
}
@ {%
  A \define{(tangent) vector field} on a smooth manifold $M$ is a smooth section
  of the tangent bundle of $M$. The set of all vector fields on $M$ is denoted
  by $C^\infty(M, \mrm{T}M)$.

  A \define{scalar field} on a smooth manifold $M$ is a smooth map
  from $M$ to $\mbb{R}$.
}
@ {%
  Recall that the \define{directional derivative} of a scalar field $f$ along
  a vector $v$ represents the degree to which $f$ changes along an infinitesimal
  vector pointing in the same direction as $v$. We will now generalize this
  notion to arbitrary smooth manifolds.
}
@ {%
  A \define{Levi-Civita connection} on a pseudo-Riemannian manifold $M$ is
  \sfixme{}.
}
@ {%
  The \define{fundamental theorem of Riemannian geometry} states that for any
  pseudo-Riemannian manifold $M$, there exists a unique Levi-Civita connection.
}
% @ {%
%   An \define{affine connection} on a smooth manifold $M$ is a map
%   $\nabla : {C^\infty(M, \mrm{T}M)}^2 \to C^\infty(M, \mrm{T}M)$
%   such that the following conditions all hold:
% }
% @@ {%
%   $\nabla$ is $\mbb{R}$-bilinear:
%   for all scalars $a, b \in \mbb{R}$ and all vector fields
%   $X, Y, Z \in C^\infty(M, \mrm{T}M)$,
%   $\nabla(a X + b Y, Z) = a \nabla(X, Z) + b \nabla(Y, Z)$ and
%   $\nabla(X, a Y + b Z) = a \nabla(X, Y) + b \nabla(X, Z)$.
%
% }
% @@ {%
%   $\nabla$ is $C^\infty(M, \mbb{R})$-linear in the first position:
%   for all scalar fields $f \in C^\infty(M, \mbb{R})$ and all vector fields
%   $X, Y \in C^\infty(M, \mrm{T}M)$,
%   $\nabla(f X, Y) = f \nabla(X, Y)$.
% }
% @@ {%
%   The \define{Leibniz rule} holds in the second position:
%   for all scalar fields $f \in C^\infty(M, \mbb{R})$ and all vector fields
%   $X, Y \in C^\infty(M, \mrm{T}M)$,
%   $\nabla(X, f Y) = \mrm{d}f(X) Y + f \nabla(X, Y)$.
% }
\end{easylist}

%\fixme{geodesics}
%\\ \fixme{Christoffel symbols}
%\\ \fixme{Tensor algebra}
%\\ \fixme{Exterior algebra / calculus}
%\\ \fixme{de Rham cohomology}
%\\ \fixme{Clifford algebra}
%\\ \fixme{Yang-Mills theory}
%\\ \fixme{Lorentz group / Minkowski spacetime}
%\\ \fixme{Banach spaces and Banach algebras}
%\\ \fixme{$C^\star$-algebras}
%\\ \fixme{Hilbert spaces}
%\\ \fixme{Sheaves on a topological space}
%\\ \fixme{synthetic differential geometry}
%\\ \fixme{Cartan / Klein geometry}
%\\ \fixme{supergeometry}
%\\ \fixme{variational calculus}
%\\ \fixme{Einstein-Hilbert action}
%\\ \fixme{electromagnetism}
%\\ \fixme{Dirac equation}
%\\ \fixme{electroweak interaction}
%\\ \fixme{strong interaction}
%\\ \fixme{Higgs mechanism}
%\\ \fixme{Yukawa interaction}
%\\ \fixme{Standard Model Lagrangian}
%\\ \fixme{supersymmetry}
%\\ \fixme{representation theory}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Linear Algebra}

\subsection{Matrices}

\begin{easylist}[itemize]
@ {%
  If $\mbs{s}$ is a commutative ring and $(m, n) \in \mbb{N}$,
  then $m \multimap_\mbs{s} n$ denotes the $\mbs{s}$-bimodule
  of $n \times m$ matrices. Sometimes, we will use the alternative notation
  $\mbs{M}_{m \times n}(\mbs{s}) = n \multimap_\mbs{s} m$.
}
@ {%
  \textbf{Theorem}:
  If $\mbs{s}$ is a field, then $m \multimap_\mbs{s} n$ is a vector space with
  $\mbs{s}$ as its field of scalars.
  Equivalently, $\msf{Vect}_\mbs{s}$ is a closed category (which means that
  it has an internal hom).
}
@ {%
  \textbf{Theorem}:
  Every matrix in $m \multimap_\mbs{s} n$ corresponds to a linear map
  in $\mbs{s}^m \to \mbs{s}^n$. For a matrix $M$, this linear map is given
  by $v \mapsto M \cdot v$. Composition of these linear maps corresponds to
  the matrix product.
}
@ {%
 There are several categories whose morphisms can be thought of as matrices:
}
@@ {%
  $\msf{Mat}_\mbs{s}$ is the category for which the objects are elements of the
  set $\{\mbs{s}^n \mid n \in \mbb{N}\}$, the hom-set between $\mbs{s}^x$ and
  $\mbs{s}^y$ is $\mbs{M}_{y \times x}(\mbs{s})$, and composition of morphisms
  is given by matrix multiplication.
}
@@ {%
  $\msf{Vect}_\mbs{s}$ is the category of vector spaces with linear maps as
  morphisms and composition of morphisms given by ordinary function composition.

  This might seem like a category relevant to matrices, but it isn't, as not
  only are there vector spaces in $\msf{Vect}_\mbs{s}$ that are
  infinite-dimensional, but there are vector spaces in $\msf{Vect}_\mbs{s}$
  whose dimension is uncountable!

  For example, define $\mbs{Unc}$ to be the vector space whose set of vectors is
  defined by
  $\{f \in \mbb{R} \to \mbb{R} \mid \card(\{x \in \mbb{R} \mid f(x) \neq 0\}) \in \mbb{N}\}$,
  whose addition is pointwise, and whose multiplication is pointwise.
  Since $\{(y \mapsto \delta(x, y)) \mid x \in \mbb{R}\}$ is a basis for
  $\mbs{Unc}$, where $\delta(x, y) = [x = y]$ is the Kronecker delta function
  on $\mbb{R}$, and $x \mapsto (y \mapsto \delta(x, y))$ is a bijection, and all
  the bases of a vector space must have the same cardinality as the dimension of
  the vector space, it must be the case that dimension of $\mbs{Unc}$ is
  $\abs{\mbb{R}}$, which is uncountable.

  While the concept of infinite matrices might seem reasonable, the idea of
  a matrix with uncountably many columns is not reasonable. Thus, an exposition
  of $\msf{Mat}_\mbs{s}$ needs to talk about $\msf{FinVect}_\mbs{s}$, the full
  subcategory of $\msf{Vect}_\mbs{s}$ consisting of only the finite-dimensional
  vector spaces (a full subcategory has the same hom-sets as its supercategory).

  Now we can describe $\msf{Mat}_\mbs{s}$ as the quotient
  of $\msf{FinVect}_\mbs{s}$ by the equivalence relation given by isomorphisms
  in $\msf{FinVect}_\mbs{s}$. Thus, $\msf{Mat}_\mbs{s}$ is the skeleton
  of $\msf{FinVect}_\mbs{s}$, which is unique up to isomorphism of categories.
}
\end{easylist}

\subsection{Matrix Product}

\begin{easylist}[itemize]
@ \sfixme{}
\end{easylist}

\subsection{Kronecker Product}

\begin{easylist}[itemize]
@ {%
  If $A \in m \multimap_\mbs{s} n$ and $B \in p \multimap_\mbs{s} q$, then the
  \define{Kronecker product} of $A$ and $B$ is defined by
  \begin{align*}
    A \otimes B
    & \in m p \multimap n q \\
    A \otimes B
    & = \mathrm{flatten}{\left(\begin{bmatrix}
    A_{11} B & \cdots & A_{1n} B \\
    \vdots   & \ddots & \vdots   \\
    A_{m1} B & \cdots & A_{mn} B \\
    \end{bmatrix}\right)}
  \end{align*}
  where
  $ \mathrm{flatten}
  \in \mbs{M}_{a \times b}(\mbs{M}_{x \times y}(\mbs{s}))
  \to \mbs{M}_{a x \times b y}(\mbs{s})$
  is the function that ``flattens'' a block matrix into a matrix of scalars,
  and $A_{xy}$ is the scalar coordinate of $A$ at position $(x, y)$.
}
@ {%
  The Kronecker product can be used to make a tensor product for
  $\msf{Mat}_\mbs{s}$, thus making it a (non-strict) monoidal closed category,
  in the following way:
}
@@ {%
  The tensor unit is the \fixme{object in $\msf{Mat}_\mbs{s}$}.
}
@@ {%
  The tensor product bifunctor $\otimes$ acts on objects of
  $\msf{Mat}_\mbs{s}$ by
  \begin{align*}
    \mbs{s}^m \otimes \mbs{s}^n & = (\mbs{s}^m \times \mbs{s}^n) / \phi \\
    {} & \phi((k x, y), (x, k y)) \\
  \end{align*}
  \vspace{-2em}
}
@@ {%
  The tensor product bifunctor $\otimes$ acts on morphisms of
  $\msf{Mat}_\mbs{s}$, which are matrices, via the Kronecker product.
}
@@ {%
  The associator and unitors are the obvious ones.
}
@@ {%
}
@ There are a large number of identities involving the Kronecker product:
@@ {%
  Since the Kronecker product is a tensor product, it is bilinear:
  \begin{align*}
    A \otimes (B + C)       & = A \otimes B + A \otimes C \\
    (A + B) \otimes C       & = A \otimes C + B \otimes C \\
    (r A) \otimes (s B)     & = r s (A \otimes B)
  \end{align*}
  and it is associative:
  \begin{align*}
    (A \otimes B) \otimes C & = A \otimes (B \otimes C)
  \end{align*}
  \vspace{-2em}
}
@@ {%
  Although the Kronecker product is \textit{not} commutative, $A \otimes B$
  is always permutation-equivalent to $B \otimes A$.
  In other words, for every pair of matrices $A \in m \multimap_\mbs{s} n$
  and $B \in p \multimap_\mbs{s} q$, there always exist permutation matrices
  $P \in n q \multimap_\mbs{s} n q$ and $Q \in m p \multimap_\mbs{s} m p$
  such that $A \otimes B = P \cdot (B \otimes A) \cdot Q$. If $A$ and $B$ are
  square, then $P = Q^{-1} = Q^\top$ and $A \otimes B$ is thus permutation
  similar to $B \otimes A$.
}
@@ {%
  The matrix product ($\cdot$) and Kronecker product ($\otimes$) obey the
  \define{mixed product property}, which says that for any appropriately
  shaped matrices $A$, $B$, $C$, and $D$:
  \begin{equation*}
  (A \otimes B) \cdot (C \otimes D) = (A \cdot C) \otimes (B \cdot D)
  \end{equation*}
  Equivalently, if $\msf{Mat}_\mbs{s}$ is thought of as a closed monoidal
  category with the Kronecker product as its tensor product, then
  $\msf{Mat}_\mbs{s}$ is a symmetric monoidal closed category.
}
@@ {%
  Similarly, the Hadamard product and the Kronecker product also have a mixed
  product property:
  \begin{equation*}
  (A \otimes B) \circ (C \otimes D) = (A \circ C) \otimes (B \circ D)
  \end{equation*}
}
@@ {%
  If $A$ and $B$ are invertible, then $(A \otimes B)^{-1} = A^{-1} \otimes B^{-1}$.

  Similarly, this holds for the pseudoinverse:
  $(A \otimes B)^{+} = A^{+} \otimes B^{+}$.
}
@@ {%
  Transposition and conjugate transposition both distribute over the Kronecker
  product: ${(A \otimes B)}^{\top} = A^\top \otimes B^\top$ and
  ${(A \otimes B)}^{\star} = A^\star \otimes B^\star$ for all $A$ and $B$.
}
@@ {%
  If $A \in m \multimap m$ and $B \in n \multimap n$ and $\sigma(-)$ gives the
  set of eigenvalues (spectrum) of a matrix, then
  $\sigma(A \otimes B) = \{xy \mid x \in \sigma(A) \land y \in \sigma(B)\}$.
}
@ {%
  The \define{Kronecker sum} is defined for $A \in m \multimap m$ and
  $B \in n \multimap n$ by $A \oplus B = A \otimes I_n + I_m \otimes B$,
  where $I_k$ is the $k \times k$ identity matrix.
}
@@ {%
  The matrix exponential transforms a Kronecker sum into a Kronecker product:

  \begin{equation*}
  \exp(A \oplus B) = \exp(A) \otimes \exp(B)
  \end{equation*}
}
\end{easylist}

\subsection{Convolution}

\begin{easylist}[itemize]
@
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Abstract Algebra}

\subsection{Ideals}

\begin{easylist}[itemize]
@ {%
  An \define{ideal} $I$ of a ring $R$ should be thought of as a particular kind
  of subset of a ring.
}
@ {%
  Specifically, for some ring $(R, +, {}\cdot{})$, a set $I$ is a
  \define{two-sided ideal} of $R$ if it satisfies two conditions:
}
@@ \textbf{Subgroup}: $(I, +)$ is a subgroup of $(R, +)$
@@ {%
  \textbf{Absorption}: For any $r \in R$ and any $i \in I$, $r \cdot i$ and
  $i \cdot r$ are both elements of $I$.
}
@ {%
  We can generalize this to the notion of a \define{left ideal} and a
  \define{right ideal}. A left ideal only requires $r \cdot i \in I$, while a
  right ideal only requires $i \cdot r \in I$.
}
@ {%
  The canonical example of an ideal is that of the even integers $2\mbb{Z}$,
  which are an ideal in $\mbb{Z}$.
}
@@ {%
  To see why this is, note that addition is closed over $2\mbb{Z}$, and that
  the additive inverse of an even integer is also even. Thus, $(2\mbb{Z}, +)$
  is a subgroup of $(\mbb{Z}, +)$. The other factor is that multiplying any
  number by an even number gives you another even number, so the absorption
  condition is satisfied.
}
@ {%
  More generally, for any integer $n$ in $\mbb{Z}$, $n\mbb{Z}$ (i.e.: the set
  $\{n \cdot x \mid x \in \mbb{Z}\}$) is an ideal in $\mbb{Z}$.
}
@ {%
  In some sense, ideals generalize the idea of the set of all values
  divisible by a given value.
}
@ Other examples:
@@ {%
  For any ring $R$, $R$ is trivially an ideal of $R$.
  This is called the \define{unit ideal} of $R$.
}
@@ {%
  For any ring $R$, $\{0_R\}$ is an ideal of $R$.
  This is called the \define{zero ideal} of $R$.
}
@@ {%
  Denote the ring of all univariate polynomials with real coefficients
  by $\mbb{R}[x]$. Then the set of all such polynomials divisible by $x^2 + 1$
  is an ideal in $\mbb{R}[x]$.
}
@ Some types of ideals:
@@ {%
  A \define{proper ideal}  is one that is not the unit ideal.
  A \define{nonzero ideal} is one that is not the zero ideal.
}
@@ {%
  The \define{maximal ideal} of a ring is the largest possible proper ideal
  for that ring.
}
@@ {%
  The \define{minimal ideal} of a ring is the smallest possible nonzero ideal
  for that ring.
}
@@ {%
  A \define{prime ideal} is an ideal $I$ such that for any $(a, b) \in R^2$,
  $a \cdot b \in I$ implies $a \in I$ or $b \in I$.
}
@@ {%
  A \define{radical} or \define{semiprime ideal} is an ideal $I$ such that
  for any $a \in R$, $a^n \in I$ implies $a \in I$.
}
@@ A \define{principal ideal} is an ideal with one generator.
@ {%
  The \define{quotient of a ring $R$ by an ideal $I$} is
  $(R / \{(a, b) \in R^2 \mid (a - b) \in I\}, +, {}\cdot{})$.
}
@ Products and sums
@@ {%
  Any two ideals $I$ and $J$ have a sum, defined as
  $I + J = \{a + b \mid a \in I \land b \in J\}$.
}
@@ {%
  Any two ideals $I$ and $J$ have a product, defined as
  \begin{equation*}
  I \times J = \{
    \psi(0) + \cdots + \psi(n)
    \mid   n \in \mbb{N}
    \rmand \phi \in \mbb{N} \to I \times J
    \rmand \psi = \pi \comp \phi
  \}
  \end{equation*}
  where $\pi : R^2 \to R$ is defined as $\pi(a, b) = a \cdot b$
}
@@ {%
  Note that $(I \cup J) \subseteq (I + J)$
  and $(I \times J) \subseteq (I \cap J)$.
}
@ The set of ideals of a ring $R$ is denoted $\mbb{I}_R$.
@ {%
  For convenience, we will define a function
  $\Phi : (A^2 \to A) \times A \to \mbb{P}(A) \to A$ by:
  \begin{equation*}
    {\Phi(f, e)(\varnothing) = e}
    ~ ~ \rmand ~ ~
    {\Phi(f, e)(\{x\} \cup X) = f(x, \Phi(f, e)(X))}
  \end{equation*}
  where $x \in A$ and $X \subseteq \mbb{P}(A)$.
  This is known as the \define{fold} of a binary operator $f$ with a unit $e$.
}
@ {%
  $(\mbb{I}_R, \subseteq, \Phi(+, \{0_R\}), \Phi(\cap, R), \{0_R\}, R)$
  is a complete modular lattice.
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Locale Theory}

\begin{easylist}[itemize]
@ These notes are primarily based on the following sources:
@@ {%
  \href{https://dl.acm.org/citation.cfm?id=64996}{%
    \textit{Topology via Logic}}
  by Steven Vickers
}
@ For some set $A$ and relation $(\#) \subseteq A \times A$:
@@ $(\#)$ is \define{reflexive} iff $\forall x \in A ~.~ x \mathrel{\#} x$.
@@ {%
  $(\#)$ is \define{transitive} iff
  $\forall (x, y, z) \in A^3 ~.~
  ((x \mathrel{\#} y) \land (y \mathrel{\#} z)) \implies (x \mathrel{\#} z)$.
}
@@ {%
  $(\#)$ is \define{symmetric} iff for all $(x, y) \in A^2$,
  $(x \mathrel{\#} y) \iff (y \mathrel{\#} x)$.
}
@@ {%
  $(\#)$ is \define{anti-symmetric} iff for all $(x, y) \in A^2$ such that
  $x \mathrel{\#} y$ and $y \mathrel{\#} x$, we have $x = y$.
}
@ {%
  A \define{preorder} is a set $P$ equipped with a relation $(\poset)$ that is
  both reflexive and transitive.
}
@@ {%
  Alternatively, a preorder can be thought of as a category $C$ in which \\
  $\forall (X, Y) \in {\objects(C)}^2 ~.~ \abs{\homset(X, Y)} \le 1$.

  For this reason, preorders are sometimes called \define{thin categories}.
}
@@ {%
  The \define{opposite preorder} for a preorder $P = (X, \poset)$ is defined as
  $\opcat{P} = (X, \tesop)$.
}
@@ {%
  A function $f : (P, \poset_P) \to (Q, \poset_Q)$ is \define{monotone} iff
  for every $(x, y) \in P^2$, it is the case that
  $x \poset_P y \implies f(x) \poset_Q f(y)$.

  The category of thin categories has monotone functions as morphisms.

  In other words, a functor between thin categories is a monotone function.
}
@ A \define{poset} is a preorder in which $(\poset)$ is anti-symmetric.
@@ {%
  Alternatively, a poset can be thought of as a category in which for any
  distinct pair of objects $(X, Y)$, we have
  $\abs{\homset(X, Y) \uplus \homset(Y, X)} \le 1$.
}
@@ {%
  Every preorder $(P, \poset)$ gives rise to a poset $(P / {\equiv}, \poset)$,
  where $a \equiv b \iff (a \poset b) \land (b \poset a)$.
}
@@ {%
  In a given poset $P$, with $X \subseteq P$ and $a \in P$, $a$ is a
  \define{lower bound} (resp. \define{upper bound}) for $X$ iff for any
  $x \in X$, $a \poset x$ (resp. $x \poset a$).
}
@@ {%
  A lower bound $a$ of $X$ is a \define{meet} if it is greater than or equal to
  any other lower bound.
}
@@ {%
  A \define{join} is dual to a meet; if $a$ is a join for $X$ in $P$, then
  $a$ is a meet for $X$ in $\opcat{P}$.
}
@ {%
  A \define{pseudolattice} is a poset in which every nonempty finite subset has
  a meet and a join.
}
@ {%
  A \define{meet-/join-semilattice} is a poset in which every finite subset
  has a meet/join.
}
@ {%
  A \define{lattice} is a poset that is both a meet-semilattice and a
  join-semilattice. Alternatively, a lattice is a pseudolattice with empty meets
  and joins (which correspond to unique maximal and minimal elements).
}
@ {%
  \textbf{Theorem}:
  A poset $P$ is a pseudolattice if it has binary meets and joins.
}
@ {%
  \textbf{Corollary}:
  If $P$ also has empty meets and joins, it is a lattice.
}
@ {%
  Thus, we will heretofore denote all finite meets and joins by binary operators
  $(\meet)$ and $(\join)$.
}
@ {%
  Infinite meets and joins will look like ${\meet}(X)$ and ${\join}(X)$
  for some $X \subseteq P$.
}
@ {%
  For lattices $L_1$ and $L_2$, a function $f : L_1 \to L_2$ is a
  \define{lattice homomorphism} if and only if for every $(a, b)$ in $L_1^2$,
  $f(a \meet_1 b) = f(a) \meet_2 f(b)$ and $f(a \join_1 b) = f(a) \join_2 f(b)$.

  A lattice homomorphism is a monotone function that respects binary meets
  and binary joins.

  The category of lattices, $\cat{Lat}$, has lattice homomorphisms
  as its morphisms.
}
@ Note that the set of all pseudolattices is closed under $(\opcat{\circ})$.
@ {%
  A poset $P$ is a \define{frame} iff every subset has join, every finite subset
  has a meet, and binary meets distribute over joins.
}
@@ In general, if $F$ is a frame, $\opcat{F}$ is not a frame.
@@ {%
  One notable exception is the \define{powerset frame} on a set $X$,
  $\mbb{P}(X)$.
}
@@ {%
  $\mbf{1} = (\{\star\}, \empty)$, the \define{inconsistent frame}, so named
  because it has $\bot = \top$.
}
@@ $\mbf{2} = (\{\bot,\top\}, \{(\bot, \top)\})$, the \define{Sierpinski frame}.
@ {%
  A \define{topology} $\Omega$ on a set $X$ is a frame such that $\Omega$ is a
  subframe of $\mbb{P}(X)$.
}
@ A \define{topological space} is a set $X$ equipped with a topology $\Omega$.
@ The elements of $\Omega$ are known as the \define{open subsets} of $X$.
@ For a poset $P$ where $x \in P$ and $S \subseteq P$:
@@ {%
  ${\uparrow}(x) = \{y \in P \mid x \poset y\}$
  is the \define{upper closure} of $x$.
}
@@ {%
  ${\uparrow}(S) = \{y \in P \mid (\exists x \in S ~ . ~ x \poset y)\}$
  is the \define{upper closure} of $S$.
}
@@ {%
  The \define{lower closure} of $x$ and $S$, denoted by ${\downarrow}(\circ)$,
  is just the upper closure in $\opcat{P}$.
}
@ Examples of topologies:
@@ The \define{discrete topology} is $\Omega = \mbb{P}(X)$.
@@ The \define{indiscrete topology} is $\Omega = \empty$.
@@ {%
  The \define{Alexandrov topology} on a poset $P$ is defined as
  $\Omega = \{{\uparrow}(x) \mid x \in P\}$.
}
@ {%
  We will heretofore denote the topology associated with any given topological
  space $X$ by $\Omega_X$.
}
@ {%
  The \define{interior} of a subset $S$ of a topological space $X$ is
  $\interior(S) = \cup \{A \in \Omega_X \mid A \subseteq S\}$
}
@@ Note that $\interior(S)$ is always the largest open set contained in $S$.
@ A subset $F \subseteq X$ is \define{closed} iff its complement is open.
@ A subset is \define{clopen} iff it is both open and closed.
@ {%
  The \define{topological closure} of a subset $S \subseteq X$ is
  $\closure(S) = \complement{(\interior(\complement{S}))}$
}
\end{easylist}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\end{document}
